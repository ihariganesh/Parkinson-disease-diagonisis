# Multi-Modal Parkinson's Disease Model Training Plan

## üìä Dataset Summary

### NTUA Parkinson Dataset
- **Total Subjects**: 80
  - PD Patients: 56
  - Non-PD Patients: 24
- **Data Types Available**:
  - DaT Scans (12-16 slices per subject)
  - MRI Scans
  - Clinical metadata

### Additional Datasets
- **Handwriting**: Available in `/Healthy/` and `/Parkinson/` folders
  - Spiral drawings
  - Wave drawings
  
## üéØ Training Goals

### Model Performance Targets

| Metric | DaT Model | Handwriting | Voice | Multi-Modal |
|--------|-----------|-------------|-------|-------------|
| **Accuracy** | 75-80% | 75-80% | 70-75% | **80-85%** |
| **AUC** | 0.75-0.80 | 0.75-0.80 | 0.70-0.75 | **0.80-0.85** |
| **Sensitivity** | >75% | >75% | >70% | **>80%** |
| **Specificity** | >75% | >75% | >70% | **>80%** |

---

## üìã Training Steps

### Step 1: Environment Setup ‚úÖ
- [x] Verify GPU availability (NVIDIA RTX 3050 6GB)
- [x] Check TensorFlow 2.20.0 installed
- [x] Verify dataset location

### Step 2: DaT Scan Model Training
**Goal**: Train CNN+LSTM model on 80 NTUA subjects

**Steps**:
1. Preprocess DaT scans (128x128, normalize, max 16 slices)
2. Split data: 70% train, 15% validation, 15% test
3. Train model with data augmentation
4. Evaluate on test set
5. Save best model to `models/dat_scan/`

**Expected**:
- Training time: 45-90 minutes (GPU)
- Target AUC: 0.75-0.80
- Model size: ~50-100 MB

**Command**:
```bash
cd /home/hari/Downloads/parkinson/parkinson-app/ml_models
python train_dat_model_ntua.py
```

### Step 3: Handwriting Model Training
**Goal**: Train ResNet50 models for spiral and wave analysis

**Steps**:
1. Load handwriting images from Healthy/ and Parkinson/ folders
2. Preprocess images (224x224 for ResNet50)
3. Train separate models for spiral and wave
4. Apply transfer learning with fine-tuning
5. Save best models to `backend/models/`

**Expected**:
- Training time: 30-60 minutes per model
- Target accuracy: 75-80%
- Models already exist and loaded!

**Status**: ‚úÖ **Models already trained and working!**

### Step 4: Voice Model Training
**Goal**: Train MFCC-based classifier for speech analysis

**Steps**:
1. Extract MFCC features from voice recordings
2. Train Random Forest or SVM classifier
3. Cross-validate performance
4. Save model to `models/speech/`

**Expected**:
- Training time: 10-20 minutes
- Target accuracy: 70-75%
- Feature extraction: 144 features per audio file

**Command**:
```bash
cd /home/hari/Downloads/parkinson/parkinson-app/ml_models
python train_speech_model.py
```

### Step 5: Multi-Modal System Validation
**Goal**: Test complete system with all three modalities

**Steps**:
1. Run comprehensive analysis on test set
2. Measure weighted ensemble performance
3. Calculate final accuracy, AUC, sensitivity, specificity
4. Generate confusion matrix and ROC curves
5. Document results

**Expected**:
- Multi-modal accuracy: 80-85%
- AUC: 0.80-0.85
- Improved performance over individual modalities

**Command**:
```bash
cd /home/hari/Downloads/parkinson/parkinson-app
python test_multimodal_system.py
```

---

## üöÄ Quick Start - Training Sequence

### Option 1: Train All Models (Recommended)
```bash
cd /home/hari/Downloads/parkinson/parkinson-app

# Activate virtual environment
source backend/ml_env/bin/activate

# Train DaT model (60-90 mins)
cd ml_models
python train_dat_model_ntua.py

# Train voice model (10-20 mins)  
python train_speech_model.py

# Validate multi-modal system
cd ..
python test_multimodal_system.py
```

**Total Time**: ~2-3 hours

### Option 2: Train Individual Models
```bash
# Just DaT model
cd ml_models
python train_dat_model_ntua.py

# Just voice model
python train_speech_model.py

# Just handwriting (already done!)
# Models at: backend/models/resnet50_spiral_best.h5
#            backend/models/resnet50_wave_best.h5
```

---

## üìà Expected Results

### Individual Modality Performance

| Modality | Accuracy | AUC | Sensitivity | Specificity |
|----------|----------|-----|-------------|-------------|
| DaT Scan | 78% | 0.77 | 80% | 75% |
| Handwriting | 76% | 0.75 | 78% | 73% |
| Voice | 72% | 0.71 | 70% | 74% |

### Multi-Modal Fusion Performance

| Metric | Expected Value |
|--------|----------------|
| **Accuracy** | **82%** |
| **AUC** | **0.81** |
| **Sensitivity** | **85%** |
| **Specificity** | **78%** |
| **Confidence Level** | High (>80%) |

**Fusion Strategy**:
- DaT: 50% weight (most reliable)
- Handwriting: 25% weight (motor symptoms)
- Voice: 25% weight (speech patterns)

---

## üîß Troubleshooting

### GPU Out of Memory
- Reduce batch size in training scripts
- Use smaller image sizes
- Enable mixed precision training

### Low Accuracy
- Increase training epochs
- Add more data augmentation
- Try different model architectures
- Balance dataset (use class weights)

### Training Too Slow
- Verify GPU is being used
- Reduce validation frequency
- Use data generators instead of loading all data

---

## üìù Next Steps After Training

1. **Update README** with actual performance metrics
2. **Document model architectures** in detail
3. **Create model cards** with limitations and usage guidelines
4. **Deploy models** to production environment
5. **Set up monitoring** for model performance
6. **Plan for retraining** as more data becomes available

---

## ‚ö†Ô∏è Important Notes

- **Data Privacy**: Ensure all patient data is anonymized
- **Clinical Validation**: Models need clinical validation before medical use
- **Regulatory Compliance**: Not FDA-approved, for research only
- **Continuous Improvement**: Models should be retrained with more data
- **Version Control**: Tag model versions with performance metrics

---

## üìö Resources

- NTUA Dataset: `/home/hari/Downloads/parkinson/ntua-parkinson-dataset/`
- Models Directory: `/home/hari/Downloads/parkinson/parkinson-app/models/`
- Training Scripts: `/home/hari/Downloads/parkinson/parkinson-app/ml_models/`
- Backend Services: `/home/hari/Downloads/parkinson/parkinson-app/backend/app/services/`

---

**Status**: Ready to begin training! üöÄ
